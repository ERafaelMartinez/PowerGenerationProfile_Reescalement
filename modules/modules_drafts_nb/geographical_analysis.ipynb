{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "rt_y-PfZl3UD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import descartes\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import urllib.request\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns; sns.set()\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BZAd1zZrl3UN"
   },
   "outputs": [],
   "source": [
    "#Import del módulo de donde se descargan los datos y se extrae.\n",
    "from modules import data_download_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6y7n2fCnmlQB",
    "outputId": "2c68af18-9d4d-4c90-996c-e77e32fe16d3"
   },
   "outputs": [],
   "source": [
    "#Descarga y extracción de archivos csv.\n",
    "\n",
    "def data_download( Eastern = True, Western = True, Unzip = True):\n",
    "    '''data_download( Eastern = True, Western = True, Unzip = True)\n",
    "    \n",
    "        This function downloads the 2006 simulated plants time series for fotovoltaic power generation. \n",
    "        It uses data provided by NREL. Downloads the files into a folder called 'data' where the extracted \n",
    "        files are also stored, if selected.\n",
    "    '''\n",
    "    if Eastern:\n",
    "        print('Downloading eastern states data:')\n",
    "        data_download_extraction.download_data('./links/eastern_states_links.csv', './')\n",
    "        print('Download finished.')\n",
    "    if Western:\n",
    "        print('Downloading western states data:')\n",
    "        data_download_extraction.download_data('./links/western_states_links.csv', './')\n",
    "        print('Download finished.')\n",
    "    if Unzip:\n",
    "        print('Exracting data files:')\n",
    "        data_download_extraction.unzip_data('./data/')\n",
    "        print('Extraction finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "PZoJzhP-l3UO"
   },
   "outputs": [],
   "source": [
    "#Creación de los dataframes con los datos. Se generan archivos csv.\n",
    "\n",
    "def get_plants_files_metadata( read = False, PATH = './data/Extracted/', UPV = True, DPV = True, to_csv = False):\n",
    "\n",
    "    '''Function returns pandas dataframes with the metadata of the files which contain the time series.\n",
    "       -UPV: solar plants with tracking technology.\n",
    "       -DPV: solar plants without tracking technology.\n",
    "    '''\n",
    "    if read:\n",
    "        #Si los archivos con datos geograficos ya están construidos solo se leen\n",
    "        if UPV and DPV:\n",
    "            data_UPV = pd.read_csv('metadata_UPV.csv')\n",
    "            data_DPV = pd.read_csv('metadata_DPV.csv')\n",
    "            return data_UPV, data_DPV\n",
    "        if UPV and not DPV: \n",
    "            data_UPV = pd.read_csv('metadata_UPV.csv')\n",
    "            return data_UPV\n",
    "        if DPV and not UPV: \n",
    "            data_DPV = pd.read_csv('metadata_DPV.csv')\n",
    "            return data_DPV\n",
    "    else:\n",
    "        if UPV and DPV:\n",
    "            data_UPV = data_download_extraction.info_df_from_data( PATH , tech = 'UPV')\n",
    "            data_DPV = data_download_extraction.info_df_from_data( PATH , tech = 'DPV')\n",
    "            if to_csv: \n",
    "                data_UPV.to_csv('./metadata_UPV.csv', index = False)\n",
    "                data_DPV.to_csv('./metadata_DPV.csv', index = False)\n",
    "            return data_UPV, data_DPV\n",
    "        if UPV and not DPV: \n",
    "            data_UPV = data_download_extraction.info_df_from_data( PATH , tech = 'UPV')\n",
    "            if to_csv: \n",
    "                data_UPV.to_csv('./metadata_UPV.csv', index = False)\n",
    "            return data_UPV\n",
    "        if DPV and not UPV: \n",
    "            data_DPV = data_download_extraction.info_df_from_data( PATH , tech = 'DPV')\n",
    "            if to_csv: \n",
    "                data_DPV.to_csv('./metadata_DPV.csv', index = False)\n",
    "            return data_DPV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "9LfWAYAY21jz"
   },
   "outputs": [],
   "source": [
    "#Descarga y extracción de archivos shape del mapa de EEUU.\n",
    "\n",
    "def get_usa_shapes():\n",
    "    \n",
    "    url = 'https://www2.census.gov/geo/tiger/GENZ2018/shp/cb_2018_us_nation_5m.zip'\n",
    "    urllib.request.urlretrieve(url, './usa_shape.zip')\n",
    "    url = 'https://www2.census.gov/geo/tiger/GENZ2018/shp/cb_2018_us_state_500k.zip'\n",
    "    urllib.request.urlretrieve(url, './usa_shape_division.zip')\n",
    "    url = 'https://www2.census.gov/geo/tiger/GENZ2018/shp/cb_2018_us_county_500k.zip'\n",
    "    urllib.request.urlretrieve(url, './usa_shape_countys.zip')\n",
    "\n",
    "    with zipfile.ZipFile('./usa_shape.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('./usa_shapes/usa_shape_nation/')\n",
    "    with zipfile.ZipFile('./usa_shape_division.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('./usa_shapes/usa_shape_states/')\n",
    "    with zipfile.ZipFile('./usa_shape_countys.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('./usa_shapes/usa_shape_countys/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generación de dataframes con puntos geograficos, acotados según una ventana máxima de \n",
    "\n",
    "def geographic_data(data_XPV_meta ):\n",
    "    '''\n",
    "    geographic_data(data_XPV_meta )\n",
    "    \n",
    "    Returns a geographic dataframe corresponding with the points of the locations on the metadata.\n",
    "    '''\n",
    "    #Creación de puntos geográficos a partir del dataframe.\n",
    "    geometry_XPV = [Point(xy) for xy in zip(data_XPV_meta.Longitude.values.astype('float64'),data_XPV_meta.Latitude.values.astype('float64'))]\n",
    "    geo_data_XPV = gpd.GeoDataFrame(data_XPV_meta, crs = 'crs', geometry = geometry_DPV)\n",
    "    return geo_data_XPV\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualización de las plantas\n",
    "\n",
    "def plants_visualisation(geo_data_XPV, map_precision = 'states', BBox = (-125.00, -66.00, 24.20, 49.50), tech = 'UPV'):\n",
    "    '''\n",
    "    plants_visualisation(geo_data_XPV, map_precision = 'states', BBox = (-125.00, -66.00, 24.20, 49.50), tech = 'UPV')\n",
    "    \n",
    "    Creates a plot within the bounding box BBox which has coordinates.\n",
    "    '''\n",
    "    #Lectura de archivo shape para generación del mapa.\n",
    "    if map_precision == 'nation':\n",
    "        usa_map = gpd.read_file('./usa_shapes/usa_shape_nation/cb_2018_us_nation_5m.shp')\n",
    "    if map_precision == 'states':\n",
    "        usa_map = gpd.read_file('./usa_shapes/usa_shape_states/cb_2018_us_state_500k.shp')\n",
    "    if map_precision == 'countys':\n",
    "        usa_map = gpd.read_file('./usa_shapes/usa_shape_countys/cb_2018_us_county_500k.shp')\n",
    "        \n",
    "    if tech == 'UPV':\n",
    "        colmap = 'YlOrBr'\n",
    "    elif tech == 'DPV':\n",
    "        colmap = 'Blues'\n",
    "    \n",
    "    fig,ax = plt.subplots(figsize = (40,15))\n",
    "    usa_map.plot(ax = ax, alpha = 1, color='black')\n",
    "    ax.set_title('Plant distribution on the USA')\n",
    "    ax.set_xlim(BBox[0],BBox[1])\n",
    "    ax.set_ylim(BBox[2],BBox[3])\n",
    "    power = geo_data_XPV['Power (MW)'].astype('float64')\n",
    "    geo_data_XPV.plot(ax = ax, markersize = 25, column = power, c = power, cmap= colmap ,marker='o', label = tech, alpha = 0.7 ,legend=True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinate_points(geo_data_XPV):\n",
    "    '''\n",
    "    coordinate_points(geo_data_XPV)\n",
    "    \n",
    "    Creates 2d array with points coordinates from the given geo_dataframe.\n",
    "    '''\n",
    "    geo_points = geo_data_XPV.geometry.values\n",
    "    points = [ np.array((geom.xy[0][0], geom.xy[1][0])) for geom in geo_points ]\n",
    "    return points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DksUbJqfvioK"
   },
   "source": [
    "Segmentation with K means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "DNdodlXrOxq3"
   },
   "outputs": [],
   "source": [
    "def geographical_plant_clustering(geo_data_XPV, N_clusters = 50 ):\n",
    "    '''\n",
    "    geographical_plant_clustering(geo_data_XPV, N_clusters = 50 )\n",
    "    \n",
    "    Clusters from the geographical coordinates of the plants. The funtion assigns a clustering class to each one of \n",
    "    the plants on the data frame and creates another data frame with the segmented centroids. In the second data \n",
    "    frame, it appends the nearest city with its own coordinates as well.\n",
    "    '''\n",
    "    #clustering\n",
    "    points = coordinate_points(geo_data_XPV)\n",
    "    kmeans = KMeans(n_clusters = N_clusters, init ='k-means++')\n",
    "    kmeans.fit(points) # Compute k-means clustering.\n",
    "    geo_data_XPV['cluster_label_kmeans'] = kmeans.fit_predict(points) # Labels of each point on geo_dataframe\n",
    "    centers = kmeans.cluster_centers_ # Coordinates of cluster centers.\n",
    "    centers_df = pd.DataFrame(centers, columns = ['center_long','center_lat'])\n",
    "\n",
    "    #calling cities database\n",
    "    us_cities = pd.read_csv('./files/uscities.csv')\n",
    "    us_cities = us_cities.filter(['city','state_id','lat','lng'], axis=1)\n",
    "    us_cities = us_cities.rename(columns={\"lat\": \"Latitude\", \"lng\": \"Longitude\"})\n",
    "    us_cities.head()\n",
    "\n",
    "    #appending nearest city from segmentation centers to centers dataframe\n",
    "    cities = []\n",
    "    states = []\n",
    "    lat = []\n",
    "    lng = []\n",
    "    for x1,y1 in zip(centers_df.center_long.values, centers_df.center_lat.values):\n",
    "        distances = []\n",
    "        for x2,y2 in zip(us_cities.Longitude.values, us_cities.Latitude.values):\n",
    "            a = np.array([x1,y1])\n",
    "            b = np.array([x2,y2])\n",
    "            distances.append(np.linalg.norm(a-b))\n",
    "\n",
    "        ind = distances.index(min(distances))\n",
    "        cities.append(us_cities.values[ind][0])\n",
    "        states.append(us_cities.values[ind][1])\n",
    "        lat.append(us_cities.values[ind][2])\n",
    "        lng.append(us_cities.values[ind][3])\n",
    "\n",
    "    #adds to dataframe data from nearest city to the centroid\n",
    "    centers_df['Nearest_city'] = cities\n",
    "    centers_df['State_near_city'] = states\n",
    "    centers_df['city_long'] = lng\n",
    "    centers_df['city_lat'] = lat\n",
    "    \n",
    "    geo_data_XPV_labeled = geo_data_XPV\n",
    "    \n",
    "    return geo_data_XPV_labeled, centers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plant_cluster_plotting(geo_data_XPV, centers_df, map_precision = 'states', BBox = (-125.00, -66.00, 24.20, 49.50), tech = 'UPV', coords = None):\n",
    "    '''\n",
    "    plant_cluster_plotting(geo_data_XPV, centers_df, map_precision = 'states', BBox = (-125.00, -66.00, 24.20, 49.50), tech = 'UPV', coords = None)\n",
    "    \n",
    "    Plots the different resulting clusters from the segmentation process.\n",
    "    '''\n",
    "    \n",
    "    #Lectura de archivo shape para generación del mapa.\n",
    "    if map_precision == 'nation':\n",
    "        usa_map = gpd.read_file('./usa_shapes/usa_shape_nation/cb_2018_us_nation_5m.shp')\n",
    "    if map_precision == 'states':\n",
    "        usa_map = gpd.read_file('./usa_shapes/usa_shape_states/cb_2018_us_state_500k.shp')\n",
    "    if map_precision == 'nation':\n",
    "        usa_map = gpd.read_file('./usa_shapes/usa_shape_countys/cb_2018_us_county_500k.shp')\n",
    "        \n",
    "    if tech == 'UPV':\n",
    "        colmap = 'YlOrBr'\n",
    "    elif tech == 'DPV':\n",
    "        colmap = 'Blues'\n",
    "        \n",
    "    fig,ax = plt.subplots(figsize = (40,15))\n",
    "    usa_map.plot(ax = ax, alpha = 1, color='gray')\n",
    "    ax.set_title('Plant clusters on USA')\n",
    "    ax.set_xlim(BBox[0],BBox[1])\n",
    "    ax.set_ylim(BBox[2],BBox[3])\n",
    "    power = geo_data_XPV['Power (MW)'].astype('float64')\n",
    "    cluster = geo_data_XPV['cluster_label_kmeans'].astype('float64')\n",
    "    geo_data_XPV.plot(ax = ax, markersize = 25, column = cluster, c = cluster, cmap= colmap ,marker='o', label = tech + ' groups', alpha = 0.75 )\n",
    "    plt.scatter(centers_df.center_long, centers_df.center_lat, c='black', s=200, alpha=0.5)\n",
    "    if coords is not None:\n",
    "        coords_df = pd.Dataframe( data = coords, coluns = ['long', 'lat'])\n",
    "        plt.scatter(coords_df.long, coords_df.lat, c='yellow', s=175, alpha=0.7)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_centroid(geo_data_XPV_labeled, centers_df, coords = (-120,25)):\n",
    "    '''\n",
    "    closest_centroid(geo_data_XPV_labeled, centers_df, coords = (-120,25))\n",
    "    \n",
    "    Calculates the nearest_centroid from a segmentation process given a coordinate position, \n",
    "    all of them given in centers_df. Returns the index of the nearest centroid, and its coordinates.\n",
    "    '''\n",
    "    long = coords[0]\n",
    "    latit = coords[1]\n",
    "    \n",
    "    distances = []\n",
    "    for x1,y1 in zip(centers_df.center_long.values, centers_df.center_lat.values):\n",
    "\n",
    "        a = np.array([coords[0], coords[1]])\n",
    "        b = np.array([x1,y1])\n",
    "        distances.append(np.linalg.norm(a-b))\n",
    "        \n",
    "    min_ = min(distances)\n",
    "    max_ = max(distances)\n",
    "\n",
    "    index_min = distances.index(min_)\n",
    "    index_max = distances.index(max_)\n",
    "\n",
    "    center_lng = centers_df['center_long'][index_min]\n",
    "    center_lat = centers_df['center_lat'][index_min]\n",
    "    \n",
    "    lng_max = centers_df['center_long'][index_max]\n",
    "    lat_max = centers_df['center_lat'][index_max]\n",
    "\n",
    "    b = np.array([lng_max,lat_max])\n",
    "    dist = np.linalg.norm(a-b)\n",
    "    \n",
    "    if  dist > max_:\n",
    "        warnings.warn(\"The selected coordinates are {0} times further than the furthest plant that belongs to the calculated centroid. Climatic variations may differ in a larger propportions to the ideal ones. Take it into account. Proceding...\".format(dist/max_)))\n",
    "    \n",
    "\n",
    "    return ind, center_lng, center_lat\n",
    "\n",
    "def cluster_group(index, geo_data_XPV_labeled):\n",
    "    '''\n",
    "    cluster_group(index, geo_data_XPV_labeled)\n",
    "    \n",
    "    Returns the metadata of only the plants on geo_data_XPV_labeled which are on the cluster group marked with index-\n",
    "    '''\n",
    "    \n",
    "    cluster_group_meta = geo_data_XPV_labeled.loc[geo_data_XPV_labeled['cluster_label_kmeans'] == index] \n",
    "    return cluster_group_meta.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(self, geo_data_XPV_labeled = None, path = None, set_points = False):\n",
    "    '''\n",
    "    read_data(self, geo_data_XPV_labeled = None, path = None, set_points = False):\n",
    "\n",
    "    Se leen los metadatos de algún grupo de plantas contenidos en el dataframe o csv indicado en\n",
    "    geo_data_XPV_labeled o en path según sea el caso. Después se extrae la información de los \n",
    "    perfiles de generación, así como de la potencia de las respectivas plantas. \n",
    "    Se extraen los valores de generación de la planta al medio día y se devuelve en el array llamado 'points'.\n",
    "    '''\n",
    "    if path is not None:\n",
    "        plants_metadata_df = pd.read_csv(path)\n",
    "    else:\n",
    "        plants_metadata_df = geo_data_XPV_labeled\n",
    "        \n",
    "    #files = [f for f in os.listdir(datapath) if os.path.isfile(os.path.join(datapath, f))] SE LEEN LOS ARCHIVOS EN PATH\n",
    "    files = geo_data_XPV_labeled['File_name']\n",
    "    power_plants_MW = geo_data_XPV_labeled['Power (MW)'].astype('float64')\n",
    "    #for file in files:    SE LEEN LOS NUMEROS QUE TIENEN EL NOMBRE DEL ARCHIVO PARA EXTRAER LA POTENCIA DE LA PLANTA.\n",
    "     #   power_plants_MW.append(int(''.join(list(filter(str.isdigit, file)))))   \n",
    "    \n",
    "    \n",
    "    self.power_plants_MW = power_plants_MW\n",
    "    points = []\n",
    "    \n",
    "    for file, MW in zip(files, power_plants_MW):\n",
    "        plant = pd.read_csv('./data/' + file, header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "        midday_data = MW*np.ones((364,2))\n",
    "        for j in range(364):\n",
    "            i=2*j+1\n",
    "            midday_data[j][1] = plant[i*int(288/2):i*int(288/2) + 1]\n",
    "        points.append(midday_data)\n",
    "    points = np.array(points) \n",
    "\n",
    "    if set_points:\n",
    "        self.points = points\n",
    "\n",
    "    return points "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "geographical_plotting.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
